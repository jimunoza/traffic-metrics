# ğŸš¦ Traffic Metrics â€“ Computer Vision for Smart Intersections

[![Python](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/)  
[![Docker](https://img.shields.io/badge/docker-ready-blue)](https://www.docker.com/)  
[![FastAPI](https://img.shields.io/badge/api-fastapi-green)](https://fastapi.tiangolo.com/)  
[![YOLOv8](https://img.shields.io/badge/detection-yolov8-orange)](https://github.com/ultralytics/ultralytics)  
[![License: MIT](https://img.shields.io/badge/license-MIT-yellow)](LICENSE)  

**Smart traffic analytics with computer vision â€” YOLO + KCF + FastAPI, Docker-ready.**

---

## ğŸ“– Overview

Traffic Metrics is a modular **computer vision system** for analyzing traffic at signalized intersections with crosswalks.  
It combines **deep learning** for detection (YOLOv8) with **classical tracking** (KCF) to provide real-time and offline metrics such as:

- Vehicle & pedestrian detection  
- Multi-object tracking with unique IDs  
- Lane occupancy and stop-line control  
- Waiting times and queue lengths (planned)  
- Red-light violations and near-miss analysis (future work)  

The project is designed for **research and prototyping**, fully reproducible with Docker.

---

## ğŸ—ï¸ Architecture

```text
Video Source (File / RTSP / Webcam)
            â”‚
        Ingest (OpenCV)
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Detection (YOLOv8) â”€â”€ Deep Learning
    â”‚ Tracking (KCF)  â”€â”€â”€â”€ Classical CV
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
        Zone Mapping (lanes, crosswalks, stop-lines)
            â”‚
        Metrics Engine (queues, speeds, waits)
            â”‚
   API (FastAPI) â”€â”€â–¶ Dashboards / Stream / DB
```

---

## ğŸ“‚ Project Structure

```
traffic-metrics/
â”‚â”€â”€ api/                # FastAPI endpoints (health, stream, etc.)
â”‚   â””â”€â”€ stream.py
â”‚â”€â”€ ingest/             # Video capture
â”‚â”€â”€ detect/             # Detection logic
â”‚â”€â”€ track/              # Tracking (KCF)
â”‚â”€â”€ metrics/            # Metrics calculation (future)
â”‚â”€â”€ viz/                # Visualization / dashboards
â”‚â”€â”€ scripts/            # CLI utilities
â”‚   â”œâ”€â”€ mark_zones.py   # GUI tool to mark lanes/crosswalks
â”‚   â”œâ”€â”€ show_zones.py   # Local validation with OpenCV
â”‚   â”œâ”€â”€ detect_mvp.py   # Basic YOLO detection
â”‚   â”œâ”€â”€ track_kcf.py    # YOLO + KCF tracking
â”‚   â””â”€â”€ detect_realtime.py / stream_fast.py
â”‚â”€â”€ configs/            # Intersection configs (zones.yaml)
â”‚â”€â”€ output/             # Processed video outputs
â”‚â”€â”€ Dockerfile
â”‚â”€â”€ docker-compose.yml
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ requirements-dev.txt
â”‚â”€â”€ .gitignore
â”‚â”€â”€ .env.example
â”‚â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Clone repo
```bash
git clone https://github.com/YOURUSER/traffic-metrics.git
cd traffic-metrics
```

### 2. Configure environment
Copy `.env.example` â†’ `.env` and set video source:
```env
VIDEO_SOURCE=/data/roswell.mov        # file (mounted from host)
# VIDEO_SOURCE=0                      # local webcam
# VIDEO_SOURCE=rtsp://user:pass@ip/   # RTSP camera
```

### 3. Build with Docker
```bash
docker compose build
docker compose up
```

API will be available at:
- `http://localhost:8000/` â†’ root  
- `http://localhost:8000/docs` â†’ Swagger docs  
- `http://localhost:8000/health` â†’ healthcheck  
- `http://localhost:8000/stream` â†’ live detections (MJPEG)  

---

## ğŸ¥ Usage Examples

### Mark intersection zones (lanes, crosswalks, stop-lines)
```bash
python scripts/mark_zones.py
```
Result saved in `configs/config.yaml`.

### Validate zones visually
```bash
python scripts/show_zones.py
```

### Run detection MVP (offline)
```bash
docker exec -it traffic_api python scripts/detect_mvp.py
```
Output saved in `output/detect_mvp.mp4`.

### Run YOLO + KCF tracking (offline)
```bash
docker exec -it traffic_api python scripts/track_kcf.py
```
Output saved in `output/track_kcf_fast.mp4`.

### Real-time detection (API stream)
```bash
open http://localhost:8000/stream
```

---

## âœ… Roadmap (Levels)

- **Level 0** â€“ Foundations: structure, Docker, API âœ…  
- **Level 1** â€“ Zone definition & validation âœ…  
- **Level 2** â€“ Detection MVP (YOLOv8) + real-time stream âœ…  
- **Level 3** â€“ Tracking with KCF (multi-object IDs) âœ…  
- **Level 4** â€“ Calibration & metric map (px â†’ meters) ğŸš§  
- **Level 5** â€“ Lane assignment & movement classification  
- **Level 6** â€“ Signal phase detection (API or vision)  
- **Level 7** â€“ Metrics v1: counts, queues, waits  
- **Level 8+** â€“ Safety analysis: near-misses, violations  

---

## ğŸ› ï¸ Requirements

- Python 3.10+ (for local tools)  
- Docker + Docker Compose  
- Optional: GPU with CUDA for faster YOLO inference  

---

## ğŸ¤ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss.  
Future improvements include multi-camera support, database integration, and advanced metrics.

---

## ğŸ“œ License

This project is licensed under the MIT License â€” see [LICENSE](LICENSE) for details.
